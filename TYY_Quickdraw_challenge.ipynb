{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TYY Quickdraw - challenge.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohyongyao/AI-Project/blob/master/TYY_Quickdraw_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI7JCKdlR_yY",
        "colab_type": "text"
      },
      "source": [
        "# Quickdraw\n",
        "\n",
        "Name: Toh Yong Yao\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5QapFEpQAbn",
        "colab_type": "code",
        "outputId": "729087ca-9dc4-49de-d3a6-c3f6dbab4bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!wget -qq https://www.dropbox.com/s/gdlb8dnjzcly51o/quickdraw.zip\n",
        "  \n",
        "!unzip -qq quickdraw.zip\n",
        "\n",
        "!rm -r __MACOSX\n",
        "!rm quickdraw.zip\n",
        "\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quickdraw  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFf-uNSSUTyF",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjAy-oR3UVJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from glob import glob\n",
        "import ntpath\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU, Add, MaxPool2D, GlobalAvgPool2D\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_CKQprGGgfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names = glob('./quickdraw/*.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxUjCp-ujYVc",
        "colab_type": "code",
        "outputId": "22b460a7-3d86-4290-a927-fa6499c3bbac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# make some class names\n",
        "class_names = []\n",
        "\n",
        "for file in file_names:\n",
        "  name = ntpath.basename(file)\n",
        "  class_names.append(name[:-4])\n",
        "  \n",
        "  \n",
        "print(class_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ant', 'cactus', 'birthday cake', 'rainbow', 'eyeglasses', 'face', 'brain', 'cookie', 'pig', 'palm tree', 'ambulance', 'alarm clock', 'donut', 'lollipop', 'angel', 'cat', 'fish', 'banana', 'bee', 'postcard']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAC-qJ-GKlxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get 1000 of each class\n",
        "\n",
        "x_data =np.array([])\n",
        "y_labels =np.array([])\n",
        "\n",
        "for i, filename in enumerate(file_names):\n",
        "  labels = [i for j in range(1000)]\n",
        "  arr = np.load(filename)\n",
        "  arr = arr[:1000]\n",
        "  if len(x_data) == 0:\n",
        "    x_data = arr\n",
        "    y_labels = np.asarray(labels)\n",
        "  else:\n",
        "    x_data = np.concatenate((x_data, arr))\n",
        "    y_labels = np.concatenate((y_labels, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5BoS6jy3bxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8072606d-0c13-4812-e82c-384c2605c9df"
      },
      "source": [
        "x_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjwOwyw0lrK4",
        "colab_type": "text"
      },
      "source": [
        "## Shuffle and split\n",
        "We should shuffle the data first to prevent having an entire class in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myTQfwZ9Pyf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle\n",
        "from sklearn.utils import shuffle\n",
        "x_data, y_labels = shuffle(x_data, y_labels, random_state=3)\n",
        "\n",
        "# Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_labels, test_size=0.1, random_state=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lolsFcvQ0wR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "413bf1a3-374f-42fa-87ac-675413a2f8a4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUn-RtiAWWq5",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data for network\n",
        "\n",
        "Each image is array of 784. Need to reshape to 28, 28, 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpIWP261r1zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 28\n",
        "input_shape = (image_size, image_size)\n",
        "num_classes = len(class_names)\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "train_step = x_train.shape[0]/batch_size\n",
        "valid_step = x_test.shape[0]/batch_size\n",
        "\n",
        "# Reshape\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size).astype('float32')\n",
        "\n",
        "# Normalize\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEvjMke5pp-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change Train Data to TF Data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "\n",
        "# Shuffle & Repeat \n",
        "train_dataset = train_dataset.shuffle(10000)\n",
        "train_dataset = train_dataset.repeat(100)\n",
        "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMwUkOhYqam_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change Validataion data to TF\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "valid_dataset = valid_dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoeGkUwoWa5Z",
        "colab_type": "text"
      },
      "source": [
        "## Model Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uf9NqhVhlIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Conv_BatchNorm(x, filters, kernel_size, strides):\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v77_SCihiEPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def projection_block(tensor, num_filters, strides):\n",
        "    # left stream\n",
        "    x = Conv_BatchNorm(tensor, filters=num_filters, kernel_size=1, strides=strides) #[v]\n",
        "    x = Conv_BatchNorm(x, filters=num_filters, kernel_size=3, strides=1)\n",
        "    x = Conv2D(filters=4*num_filters, kernel_size=1, strides=1)(x)  # notice: filters=4*num_filters\n",
        "    x = BatchNormalization()(x)\n",
        " \n",
        "    # right stream\n",
        "    proj_x = Conv2D(filters=4*num_filters, kernel_size=1, strides=strides)(tensor)  # notice: filters=4*num_filters\n",
        "    proj_x = BatchNormalization()(proj_x)\n",
        " \n",
        "    x = Add()([x, proj_x])\n",
        "    x = ReLU()(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTo-PVD5h2-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(orig_x, num_filters):\n",
        "    x = Conv_BatchNorm(orig_x, filters=num_filters, kernel_size=1, strides=1)\n",
        "    x = Conv_BatchNorm(x, filters=num_filters, kernel_size=3, strides=1)\n",
        "    x = Conv2D(filters=4*num_filters, kernel_size=1, strides=1)(x)  # notice: filters=4*num_filters\n",
        "    x = BatchNormalization()(x)\n",
        " \n",
        "    x = Add()([x, orig_x])\n",
        "    x = ReLU()(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KvWtPr8hvzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_block(x, filters, reps, strides):\n",
        "    x = projection_block(x, num_filters=filters, strides=strides)\n",
        "    for _ in range(reps-1):\n",
        "        x = identity_block(x, num_filters=filters)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsBd-gmgMV1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Inp = Input(shape=(28, 28, 1),name=\"Inp\")\n",
        "\n",
        "x = Conv_BatchNorm(Inp, filters=64, kernel_size=7, strides=2)  \n",
        "x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        " \n",
        "x = resnet_block(x, filters=64, reps=2, strides=1)\n",
        "x = resnet_block(x, filters=128, reps=2, strides=2)  \n",
        "x = resnet_block(x, filters=256, reps=2, strides=2) \n",
        "x = resnet_block(x, filters=512, reps=2, strides=2) \n",
        " \n",
        "x = GlobalAvgPool2D()(x)  \n",
        " \n",
        "output = Dense(20, activation='softmax')(x)  \n",
        " \n",
        "model = Model(Inp, output,name='Resnet18')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOUJWFmyiQ4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer\n",
        "opt = tf.keras.optimizers.Adam(lr = learning_rate)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer= opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul6nwhThWeyp",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhEqemq6MWzg",
        "colab_type": "code",
        "outputId": "d5d163cd-2019-4cb5-adce-24298dce98f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "epochs = 7\n",
        "\n",
        "hist = model.fit(train_dataset,\n",
        "                 steps_per_epoch=train_step,\n",
        "                 batch_size = batch_size,\n",
        "                 epochs=epochs,\n",
        "                 verbose=1,\n",
        "                 callbacks = None,\n",
        "                 validation_data=valid_dataset, \n",
        "                 validation_steps=valid_step)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "563/562 [==============================] - 34s 61ms/step - loss: 1.8108 - accuracy: 0.5694 - val_loss: 1.4890 - val_accuracy: 0.5536\n",
            "Epoch 2/7\n",
            "563/562 [==============================] - 33s 59ms/step - loss: 0.9083 - accuracy: 0.7498 - val_loss: 2.6337 - val_accuracy: 0.6290\n",
            "Epoch 3/7\n",
            "563/562 [==============================] - 33s 59ms/step - loss: 0.7676 - accuracy: 0.7890 - val_loss: 0.8543 - val_accuracy: 0.7763\n",
            "Epoch 4/7\n",
            "563/562 [==============================] - 34s 60ms/step - loss: 0.7086 - accuracy: 0.8104 - val_loss: 1.6544 - val_accuracy: 0.6339\n",
            "Epoch 5/7\n",
            "563/562 [==============================] - 34s 60ms/step - loss: 0.6671 - accuracy: 0.8215 - val_loss: 0.7008 - val_accuracy: 0.7917\n",
            "Epoch 6/7\n",
            "563/562 [==============================] - 34s 60ms/step - loss: 0.5920 - accuracy: 0.8421 - val_loss: 0.6876 - val_accuracy: 0.8229\n",
            "Epoch 7/7\n",
            "563/562 [==============================] - 34s 60ms/step - loss: 0.6018 - accuracy: 0.8403 - val_loss: 3.3006 - val_accuracy: 0.6101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WE8zDlbpWK0",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNTlIrgSpXei",
        "colab_type": "code",
        "outputId": "404887fa-6e4d-43ae-8abd-25c2d34d1078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(valid_dataset, steps=valid_step)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/62 [==============================] - 1s 15ms/step - loss: 3.3006 - accuracy: 0.6101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.3005623817443848, 0.6101190447807312]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}